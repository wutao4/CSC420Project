import matplotlib.pyplot as plt


##################################################################
#                   Plot charts for demonstrating                #
##################################################################

# Test accuracy lists (for 100 epochs)
shallow = [
    0.44067796610169485, 0.5730117340286832, 0.589960886571056, 0.6160365058670143, 0.6088657105606258,
    0.6232073011734028, 0.622555410691004, 0.621903520208605, 0.6297262059973925, 0.6310299869621904,
    0.6290743155149935, 0.6388526727509778, 0.6434159061277706, 0.6427640156453716, 0.6427640156453716,
    0.6473272490221643, 0.6473272490221643, 0.6421121251629727, 0.6636245110821382, 0.6740547588005215,
    0.666232073011734, 0.668187744458931, 0.6694915254237288, 0.668187744458931, 0.6740547588005215,
    0.6701434159061279, 0.666232073011734, 0.666232073011734, 0.6747066492829206, 0.7275097783572361,
    0.7666232073011734, 0.7724902216427639, 0.7672750977835725, 0.7718383311603652, 0.7705345501955673,
    0.7750977835723599, 0.8083441981747066, 0.8142112125162972, 0.8050847457627118, 0.8089960886571056,
    0.8148631029986962, 0.8135593220338984, 0.8129074315514994, 0.8161668839634941, 0.8246414602346807,
    0.8246414602346807, 0.8129074315514994, 0.8226857887874837, 0.8246414602346807, 0.8187744458930901,
    0.817470664928292, 0.818122555410691, 0.8213820078226859, 0.8246414602346807, 0.8226857887874837,
    0.8226857887874837, 0.8246414602346807, 0.8194263363754889, 0.8194263363754889, 0.8194263363754889,
    0.8135593220338984, 0.8220338983050849, 0.8292046936114733, 0.8259452411994785, 0.8298565840938721,
    0.8272490221642763, 0.8259452411994785, 0.8259452411994785, 0.8279009126466754, 0.8305084745762712,
    0.8272490221642763, 0.8252933507170794, 0.8279009126466754, 0.8252933507170794, 0.8311603650586702,
    0.8272490221642763, 0.8272490221642763, 0.8279009126466754, 0.8265971316818775, 0.831812255541069,
    0.8311603650586702, 0.8285528031290742, 0.8279009126466754, 0.8272490221642763, 0.8292046936114733,
    0.8298565840938721, 0.8259452411994785, 0.8279009126466754, 0.8279009126466754, 0.8272490221642763,
    0.8252933507170794, 0.8259452411994785, 0.8252933507170794, 0.8265971316818775, 0.8252933507170794,
    0.8252933507170794, 0.8252933507170794, 0.8265971316818775, 0.8259452411994785, 0.8259452411994785
]
large_resnet = [
    0.3318122555410691, 0.5964797913950456, 0.6349413298565841, 0.4680573663624511, 0.5795306388526728,
    0.6838331160365059, 0.7444589308996089, 0.7685788787483703, 0.7894393741851369, 0.7848761408083442,
    0.8024771838331161, 0.8272490221642764, 0.8246414602346805, 0.8389830508474576, 0.8324641460234681,
    0.8383311603650587, 0.8455019556714471, 0.8318122555410691, 0.8285528031290743, 0.8500651890482399,
    0.7653194263363755, 0.833116036505867, 0.8396349413298566, 0.8422425032594524, 0.7744458930899609,
    0.8448500651890483, 0.8650586701434159, 0.8441981747066493, 0.8650586701434159, 0.8572359843546284,
    0.8722294654498044, 0.8402868318122555, 0.877444589308996, 0.8657105606258149, 0.8754889178617992,
    0.8650586701434159, 0.878748370273794, 0.8833116036505867, 0.8767926988265972, 0.8735332464146024,
    0.8767926988265972, 0.8761408083441982, 0.8846153846153846, 0.8846153846153846, 0.8885267275097783,
    0.8761408083441982, 0.8741851368970013, 0.8872229465449805, 0.8741851368970013, 0.8891786179921773,
    0.8794002607561929, 0.8813559322033898, 0.878096479791395, 0.8878748370273793, 0.8859191655801826,
    0.8813559322033898, 0.8794002607561929, 0.8859191655801826, 0.8885267275097783, 0.8859191655801826,
    0.8872229465449805, 0.8904823989569752, 0.8898305084745762, 0.8885267275097783, 0.8924380704041721,
    0.8956975228161669, 0.8917861799217731, 0.8930899608865711, 0.8904823989569752, 0.8846153846153846,
    0.8872229465449805, 0.8950456323337679, 0.8878748370273793, 0.894393741851369, 0.8891786179921773,
    0.8911342894393742, 0.8911342894393742, 0.8911342894393742, 0.8924380704041721, 0.8898305084745762,
    0.8930899608865711, 0.8924380704041721, 0.8956975228161669, 0.89374185136897, 0.8924380704041721,
    0.894393741851369, 0.8930899608865711, 0.8917861799217731, 0.8930899608865711, 0.894393741851369,
    0.8924380704041721, 0.89374185136897, 0.8924380704041721, 0.8924380704041721, 0.8930899608865711,
    0.8930899608865711, 0.8930899608865711, 0.8930899608865711, 0.8930899608865711, 0.8930899608865711
]
resnet = [
    0.7144719687092569, 0.7183833116036505, 0.7020860495436767, 0.7731421121251629, 0.7764015645371578,
    0.8233376792698827, 0.8350717079530638, 0.8370273794002607, 0.8324641460234681, 0.8279009126466753,
    0.8598435462842242, 0.8533246414602347, 0.8194263363754889, 0.8513689700130378, 0.8754889178617992,
    0.8461538461538461, 0.8565840938722294, 0.8683181225554107, 0.8702737940026075, 0.8468057366362451,
    0.863754889178618, 0.8754889178617992, 0.8650586701434159, 0.8741851368970013, 0.8839634941329857,
    0.8846153846153846, 0.864406779661017, 0.863102998696219, 0.8722294654498044, 0.8657105606258149,
    0.8800521512385919, 0.8696219035202086, 0.8754889178617992, 0.8794002607561929, 0.8748370273794003,
    0.8650586701434159, 0.8891786179921773, 0.8754889178617992, 0.8839634941329857, 0.8917861799217731,
    0.8898305084745762, 0.8852672750977836, 0.8878748370273793, 0.8807040417209909, 0.8865710560625815,
    0.8859191655801826, 0.8813559322033898, 0.8852672750977836, 0.8911342894393742, 0.8885267275097783,
    0.8885267275097783, 0.8963494132985659, 0.8904823989569752, 0.8852672750977836, 0.8904823989569752,
    0.8846153846153846, 0.8872229465449805, 0.8865710560625815, 0.8911342894393742, 0.8891786179921773,
    0.8852672750977836, 0.8898305084745762, 0.8846153846153846, 0.8917861799217731, 0.894393741851369,
    0.894393741851369, 0.8917861799217731, 0.8983050847457628, 0.8976531942633638, 0.8963494132985659,
    0.8983050847457628, 0.8956975228161669, 0.8976531942633638, 0.8983050847457628, 0.8983050847457628,
    0.8989569752281616, 0.8956975228161669, 0.8950456323337679, 0.8996088657105606, 0.894393741851369,
    0.8950456323337679, 0.8956975228161669, 0.894393741851369, 0.8924380704041721, 0.8950456323337679,
    0.8924380704041721, 0.89374185136897, 0.8950456323337679, 0.894393741851369, 0.8950456323337679,
    0.894393741851369, 0.8976531942633638, 0.8956975228161669, 0.894393741851369, 0.8950456323337679,
    0.8956975228161669, 0.8956975228161669, 0.8956975228161669, 0.8956975228161669, 0.8956975228161669
]


# Plot the learning curve
def learning_curve():
    epochs = [e+1 for e in range(len(resnet))]
    plt.hlines(0.5654, 0, len(resnet), label='PCA accuracy')
    plt.plot(epochs, shallow, label='ShallowCNN')
    plt.plot(epochs, large_resnet, label='LargeResNet')
    plt.plot(epochs, resnet, label='ResNet')
    plt.title('Learning Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Test Accuracy')
    plt.legend()
    plt.show()


if __name__ == '__main__':
    print("----------- start -------------")

    learning_curve()

    print("------------ end --------------")
